{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dacc3e8-6f07-403f-9721-1ad171800b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "import onnxruntime\n",
    "print(\"Path del modulo importato:\", onnxruntime.__file__)\n",
    "print(\"Execution Providers disponibili:\", onnxruntime.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02cce847-0faf-4884-91b7-814c7cefce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess an image for ResNet-50 ONNX inference.\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "        image_tensor = preprocess(image).unsqueeze(0).numpy()\n",
    "        return image_tensor.astype(np.float32)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error while preprocessing '{image_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91844a53-2189-48fd-a61c-93fffadbe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_resnet50_onnx(model_path=\"models/resnet50_imagenet.onnx\"):\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        \n",
    "        model = models.resnet50(pretrained=True).eval()\n",
    "        \n",
    "        dummy_input = torch.randn(1, 3, 224, 224)\n",
    "        torch.onnx.export(\n",
    "            model, dummy_input, model_path,\n",
    "            export_params=True, opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'], output_names=['output'],\n",
    "            dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "        )\n",
    "        print(\"Exported ResNet-50 model to ONNX:\", model_path)\n",
    "    else:\n",
    "        print(\"ONNX model already exists:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a610b10e-a91d-4bd9-bde9-e36d94f967ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session_onnx(model_path = \"models/resnet50_imagenet.onnx\"):\n",
    "    sess_options = ort.SessionOptions()\n",
    "\n",
    "    providers = ['VitisAIExecutionProvider']\n",
    "    \n",
    "    try:\n",
    "        session = ort.InferenceSession(\n",
    "            model_path, \n",
    "            providers=providers,\n",
    "            sess_options=sess_options\n",
    "        )\n",
    "        \n",
    "        if 'VitisAIExecutionProvider' not in active_providers:\n",
    "            print(\"ATTENZIONE: Il VitisAIExecutionProvider non è stato utilizzato come execution provider.\")\n",
    "            print(\"Verifica la configurazione del sistema Vitis AI.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERRORE nella creazione della sessione ONNX: {e}\")\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8bd35b94-9ce3-4d9a-b8a5-61baeb03dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = create_session_onnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abaeab77-e152-4451-a1cc-407012d3a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricate 50000 etichette ImageNet.\n"
     ]
    }
   ],
   "source": [
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\"\"\"\n",
    "Qui utilizziamo il labels.txt (nella forma --> ILSVRC2012_val_00000001_n01751748.JPEG 65 sea_snake)\n",
    "per estrarre il path delle immagini nel dataset\n",
    "\"\"\"\n",
    "def load_imagenet_labels(labels_file=\"dataset/labels.txt\"):\n",
    "    with open(labels_file) as f:\n",
    "        labels = [line.strip() for line in f.readlines()]\n",
    "    return labels\n",
    "\n",
    "try:\n",
    "    labels = load_imagenet_labels()\n",
    "    print(f\"Caricate {len(labels)} etichette ImageNet.\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore nel caricamento delle etichette: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d39ec940-f96d-47d9-b7a4-a40ce2602ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funzione di inferenza configurata.\n"
     ]
    }
   ],
   "source": [
    "# Funzione di inferenza\n",
    "def run_inference(image_path, session):\n",
    "    # Preprocessing dell'immagine\n",
    "    input_data = preprocess_image(image_path)\n",
    "    \n",
    "    # Esecuzione dell'inferenza\n",
    "    start_time = time.time()\n",
    "    predictions = session.run([output_name], {input_name: input_data})[0]\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    # Elaborazione dei risultati\n",
    "    predictions = predictions[0]  # Rimuovi la dimensione del batch\n",
    "    top5_indices = np.argsort(predictions)[-5:][::-1]\n",
    "    top5_results = [(labels[idx], predictions[idx], idx) for idx in top5_indices]\n",
    "    \n",
    "    return top5_results, inference_time\n",
    "\n",
    "print(\"Funzione di inferenza configurata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50c3417a-0d80-4190-bcfd-0b67c1e9ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurazione dei parametri MLPerf...\n",
      "Parametri MLPerf configurati:\n",
      "  framework: ONNX Runtime\n",
      "  backend: Vitis AI\n",
      "  hardware: AMD NPU\n",
      "  model: ResNet50 v1.5\n",
      "  scenario: Offline\n",
      "  division: Open\n",
      "  category: Image Classification\n",
      "  precision: FP32\n",
      "\n",
      "Esecuzione di un test di inferenza su dataset/val_images_flat/ILSVRC2012_val_00000001_n01751748.JPEG...\n",
      "Tempo di inferenza: 26.11 ms\n",
      "Top 5 predizioni:\n",
      "  ILSVRC2012_val_00000540_n03825788.JPEG 680 nipple: 55.12% (indice: 539)\n",
      "  ILSVRC2012_val_00000483_n02814860.JPEG 437 beacon: 52.29% (indice: 482)\n",
      "  ILSVRC2012_val_00000440_n02097298.JPEG 199 Scotch_terrier: 52.02% (indice: 439)\n",
      "  ILSVRC2012_val_00000077_n02087394.JPEG 159 Rhodesian_ridgeback: 51.34% (indice: 76)\n",
      "  ILSVRC2012_val_00000443_n07718747.JPEG 944 artichoke: 50.01% (indice: 442)\n"
     ]
    }
   ],
   "source": [
    "# Parametri MLPerf\n",
    "print(\"\\nConfigurazione dei parametri MLPerf...\")\n",
    "MLPERF_CONFIG = {\n",
    "    \"framework\": \"ONNX Runtime\",\n",
    "    \"backend\": \"Vitis AI\",\n",
    "    \"hardware\": \"AMD NPU\",\n",
    "    \"model\": \"ResNet50 v1.5\",\n",
    "    \"scenario\": \"Offline\",\n",
    "    \"division\": \"Open\",\n",
    "    \"category\": \"Image Classification\",\n",
    "    \"precision\": \"FP32\",  # Questo cambierà quando quantizzeremo il modello\n",
    "}\n",
    "\n",
    "print(\"Parametri MLPerf configurati:\")\n",
    "for k, v in MLPERF_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Test su un'immagine singola per verifica\n",
    "test_image = \"dataset/val_images_flat/ILSVRC2012_val_00000001_n01751748.JPEG\"  # Sostituisci con un'immagine di test\n",
    "\n",
    "if os.path.exists(test_image):\n",
    "    print(f\"\\nEsecuzione di un test di inferenza su {test_image}...\")\n",
    "    top5, inference_time = run_inference(test_image, session)\n",
    "    \n",
    "    print(f\"Tempo di inferenza: {inference_time*1000:.2f} ms\")\n",
    "    print(\"Top 5 predizioni:\")\n",
    "    for label, score, idx in top5:\n",
    "        print(f\"  {label}: {score:.2f}% (indice: {idx})\")\n",
    "else:\n",
    "    print(f\"Immagine di test {test_image} non trovata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66ba6f-2bb0-4d3d-a1eb-8a72b82e8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per eseguire il benchmark MLPerf\n",
    "def run_mlperf_benchmark(image_dir=\"dataset/val_images_flat\", batch_process=False, gt_path = \"dataset/labels.txt\"):\n",
    "    image_files = []\n",
    "    with open(gt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            filename = line.strip().split()[0]\n",
    "            filename = image_dir + \"/\" + filename\n",
    "            image_files.append(filename)\n",
    "    \n",
    "    print(f\"\\nEsecuzione del benchmark su {len(image_files)} immagini...\")\n",
    "\n",
    "    results = {\n",
    "        \"correct_top1\": 0,\n",
    "        \"correct_top5\": 0,\n",
    "        \"total\": len(image_files),\n",
    "        \"inference_times\": [],\n",
    "        \"predictions\": []\n",
    "    }\n",
    "\n",
    "    start_time_total = time.time()\n",
    "\n",
    "    for i, img_path in enumerate(tqdm.tqdm(image_files)):\n",
    "        try:\n",
    "            top5, inference_time = run_inference(img_path, session)\n",
    "            results[\"inference_times\"].append(inference_time)\n",
    "\n",
    "            # Salva le top-5 predizioni come tupla di 5 classi predette\n",
    "            top5_classes = tuple(pred[2] for pred in top5[:5])\n",
    "            results[\"predictions\"].append(top5_classes)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nell'elaborazione dell'immagine {img_path}: {e}\")\n",
    "\n",
    "    total_time = time.time() - start_time_total\n",
    "\n",
    "    # Calcola le metriche\n",
    "    results[\"total_time\"] = total_time\n",
    "    results[\"images_per_sec\"] = total_images / total_time\n",
    "    results[\"avg_inference_time\"] = np.mean(results[\"inference_times\"]) if results[\"inference_times\"] else 0\n",
    "    results[\"std_inference_time\"] = np.std(results[\"inference_times\"]) if results[\"inference_times\"] else 0\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7300b43-6f48-4bcf-b2fc-83043cb0561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esegui il benchmark completo\n",
    "print(\"\\nEsecuzione del benchmark MLPerf completo...\")\n",
    "\n",
    "dataset_dir = \"dataset/val_images_flat\"\n",
    "full_results = run_mlperf_benchmark(dataset_dir)\n",
    "\n",
    "# Risultati del benchmark\n",
    "print(\"\\nRisultati del benchmark MLPerf:\")\n",
    "print(f\"  Immagini elaborate: {full_results['total']}\")\n",
    "print(f\"  Tempo totale: {full_results['total_time']:.2f} secondi\")\n",
    "print(f\"  Throughput: {full_results['images_per_sec']:.2f} immagini/secondo\")\n",
    "print(f\"  Latenza media: {full_results['avg_inference_time']*1000:.2f} ms\")\n",
    "\n",
    "# Salvataggio dei risultati nel formato MLPerf\n",
    "mlperf_results = {\n",
    "    \"mlperf_benchmark\": {\n",
    "        \"framework\": MLPERF_CONFIG[\"framework\"],\n",
    "        \"backend\": MLPERF_CONFIG[\"backend\"],\n",
    "        \"hardware\": MLPERF_CONFIG[\"hardware\"],\n",
    "        \"model\": MLPERF_CONFIG[\"model\"],\n",
    "        \"scenario\": MLPERF_CONFIG[\"scenario\"],\n",
    "        \"division\": MLPERF_CONFIG[\"division\"],\n",
    "        \"category\": MLPERF_CONFIG[\"category\"],\n",
    "        \"precision\": MLPERF_CONFIG[\"precision\"],\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"total_images\": full_results[\"total\"],\n",
    "        \"total_time_seconds\": full_results[\"total_time\"],\n",
    "        \"images_per_second\": full_results[\"images_per_sec\"],\n",
    "        \"average_latency_ms\": full_results[\"avg_inference_time\"] * 1000,\n",
    "        \"latency_std_ms\": full_results[\"std_inference_time\"] * 1000,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salva i risultati in un file JSON\n",
    "results_file = \"mlperf_results_resnet50_amd_npu.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(mlperf_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nRisultati MLPerf salvati in {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201a936-169d-47c1-b6c1-1b31b58d81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_GT(imagenet_val_map = \"dataset/labels.txt\"):\n",
    "    ground_truth = {}\n",
    "    try:\n",
    "        with open(imagenet_val_map, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 2:\n",
    "                    # Il formato è: nome_file ID_classe [nome_classe]\n",
    "                    image_name = parts[0]\n",
    "                    class_id = int(parts[1])\n",
    "                    ground_truth[image_name] = class_id\n",
    "        \n",
    "        print(f\"Caricate {len(ground_truth)} etichette di ground truth.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel caricamento del file delle etichette: {e}\")\n",
    "        return None\n",
    "\n",
    "    return ground_truth\n",
    "\n",
    "def compute_accuracy_top_1_5(predictions, ground_truth):\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    processed_images = 0\n",
    "\n",
    "    # Ottieni le etichette GT nello stesso ordine del file\n",
    "    gt_labels = list(ground_truth.values())\n",
    "\n",
    "    if len(predictions) != len(gt_labels):\n",
    "        print(f\"Errore: numero di predizioni ({len(predictions)}) diverso dal numero di etichette GT ({len(gt_labels)}).\")\n",
    "        return None\n",
    "\n",
    "    for pred, gt in zip(predictions, gt_labels):\n",
    "        processed_images += 1\n",
    "\n",
    "        if gt == pred[0]:\n",
    "            correct_top1 += 1\n",
    "        if gt in pred:\n",
    "            correct_top5 += 1\n",
    "\n",
    "    top1_accuracy = correct_top1 / processed_images\n",
    "    top5_accuracy = correct_top5 / processed_images\n",
    "\n",
    "    accuracy = {\n",
    "        \"top1\": top1_accuracy,\n",
    "        \"top5\": top5_accuracy,\n",
    "        \"total_images\": processed_images\n",
    "    }\n",
    "\n",
    "    print(f\"Immagini elaborate: {processed_images}\")\n",
    "    print(f\"Accuratezza Top-1: {top1_accuracy*100:.2f}%\")\n",
    "    print(f\"Accuratezza Top-5: {top5_accuracy*100:.2f}%\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "ground_truth = extract_GT(imagenet_val_map = \"dataset/labels.txt\")\n",
    "accuracy_results = compute_accuracy_top_1_5(full_results[\"predictions\"], ground_truth)\n",
    "\n",
    "# Aggiorna i risultati MLPerf con i dati di accuratezza\n",
    "mlperf_results[\"accuracy_metrics\"] = {\n",
    "    \"top1_accuracy\": accuracy_results[\"top1\"],\n",
    "    \"top5_accuracy\": accuracy_results[\"top5\"]\n",
    "}\n",
    "\n",
    "# Aggiorna il file dei risultati\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(mlperf_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nRisultati MLPerf aggiornati con le metriche di accuratezza in {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627aa248-ef68-4318-9dca-808d12566130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generazione del rapporto di submission MLPerf\n",
    "def generate_mlperf_report(results, config, output_file=\"mlperf_report.md\"):\n",
    "    \"\"\"\n",
    "    Genera un rapporto in formato Markdown per la submission MLPerf\n",
    "    \"\"\"\n",
    "    report = f\"\"\"# MLPerf Inference Benchmark Report\n",
    "\n",
    "## Submission Details\n",
    "\n",
    "- **Framework**: {config[\"framework\"]}\n",
    "- **Backend**: {config[\"backend\"]}\n",
    "- **Hardware**: {config[\"hardware\"]}\n",
    "- **Model**: {config[\"model\"]}\n",
    "- **Scenario**: {config[\"scenario\"]}\n",
    "- **Division**: {config[\"division\"]}\n",
    "- **Category**: {config[\"category\"]}\n",
    "- **Precision**: {config[\"precision\"]}\n",
    "- **Date**: {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "- **Total Images**: {results[\"performance_metrics\"][\"total_images\"]}\n",
    "- **Total Time**: {results[\"performance_metrics\"][\"total_time_seconds\"]:.2f} seconds\n",
    "- **Throughput**: {results[\"performance_metrics\"][\"images_per_second\"]:.2f} images/second\n",
    "- **Average Latency**: {results[\"performance_metrics\"][\"average_latency_ms\"]:.2f} ms\n",
    "- **Latency Standard Deviation**: {results[\"performance_metrics\"][\"latency_std_ms\"]:.2f} ms\n",
    "\n",
    "## Accuracy Metrics\n",
    "\n",
    "- **Top-1 Accuracy**: {results[\"accuracy_metrics\"][\"top1_accuracy\"]*100:.2f}%\n",
    "- **Top-5 Accuracy**: {results[\"accuracy_metrics\"][\"top5_accuracy\"]*100:.2f}%\n",
    "\n",
    "## System Configuration\n",
    "\n",
    "- **CPU**: AMD Ryzen (specifiche dettagliate)\n",
    "- **NPU**: AMD NPU (specifiche dettagliate)\n",
    "- **Memory**: (specifiche del sistema)\n",
    "- **OS**: (sistema operativo in uso)\n",
    "- **Software Stack**: Ryzen AI 1.4.0, ONNX Runtime, Vitis AI\n",
    "\n",
    "## Methodology\n",
    "\n",
    "This submission follows the MLPerf Inference Rules for the Open Division, Image Classification task.\n",
    "The benchmark was performed using the ImageNet validation dataset with 50,000 images across 1,000 classes.\n",
    "\n",
    "### Pre-processing Steps\n",
    "- Resize to 256x256\n",
    "- Center crop to 224x224\n",
    "- Normalize with ImageNet mean and std values\n",
    "\n",
    "### Post-processing Steps\n",
    "- Softmax applied to model outputs\n",
    "- Top-5 classes extracted by confidence\n",
    "\n",
    "## Notes\n",
    "\n",
    "This is an experimental submission for academic purposes.\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "# Genera il rapporto\n",
    "report_file = generate_mlperf_report(mlperf_results, MLPERF_CONFIG)\n",
    "print(f\"\\nRapporto MLPerf generato in {report_file}\")\n",
    "print(\"Questo rapporto può essere utilizzato come base per la tua submission MLPerf.\")\n",
    "\n",
    "print(\"\\nIl processo di benchmark per MLPerf è stato completato con successo!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
