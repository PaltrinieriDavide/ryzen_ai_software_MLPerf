# MLPerf Inference Submission with Ryzen AI

This repository contains the code, results, and submission files for running MLPerf™ Inference benchmarks using Ryzen™ AI software on an NPU.

## Folder Structure

Below is an overview of the main directories and their contents.

### `inference-master/`

This folder contains all the source code developed to run the MLPerf Inference benchmarks for various scenarios.

-   **Purpose**: Houses the primary implementation for running MLPerf tests with the Ryzen AI software stack.
-   **Contents**:
    -   `npu_offline.py`, `npu_singlestream.py`, `npu_multistream.py`, `npu_server.py`: Python scripts implementing the System Under Test (SUT) for each of the four MLPerf scenarios.
    -   `mlperf.conf`: Configuration file for the MLPerf LoadGen.
    -   `loadgen/`: The official MLPerf LoadGen submodule.
    -   `results/`: Contains all the generated output files from our test runs, including:
        -   `mlperf_log_summary.txt` files for each scenario (Offline, SingleStream, etc.).
        -   Results for different processing units (CPU, GPU, NPU).

### `MLPerf_submission/`

This directory is structured according to the official MLPerf submission rules and contains all the necessary components for our official **Offline scenario** submission.

-   **Purpose**: To package the results for an official MLPerf submission.
-   **Contents**:
    -   `code/`: The source code for the benchmark being submitted.
    -   `measurements/`: Configuration files.
    -   `results/`: LoadGen generated results and logs.
    -   `systems/`: A description file (`.json`) detailing the hardware and software configuration of the system under test.

### `monitor_scripts/`

This folder contains scripts used to monitor the NPU's performance and utilization during the benchmark runs.

-   **Purpose**: To collect real-time hardware metrics from the NPU.
-   **Contents**:
    -   A Python script that periodically executes `xrt-smi` (Xilinx Runtime System Management Interface) to capture data such as NPU utilization of its partitions.

### `pipeline_scripts/`

This directory holds the scripts required for the model preparation and quantization pipeline.

-   **Purpose**: To convert and optimize the original model for inference on the NPU.
-   **Contents**:
    -   **Model Export**: A script to export the original ResNet50 FP32 model into the ONNX format.
    -   **Model Quantization**: A script to perform post-training quantization on the ONNX model, converting it to INT8 or BFLOAT16 precision.
    -   **Dataset Preparation**: A script to prepare the calibration dataset required by the quantization process from the original ImageNet validation set.

### `power_measurements/`

This folder contains power and frequency measurement data collected during the benchmark execution.

-   **Purpose**: To analyze the power consumption and performance characteristics of the system under different workloads and power modes.
-   **Contents**:
    -   Raw data logs generated by the **AMDuProf** profiling tool, detailing frequency and power consumption for the CPU, GPU, and NPU.
    -   Power data is included for each of the NPU's power modes.
    -   An Excel spreadsheet (`.xlsx`) containing consolidated data, calculations, and charts created for the final report.
